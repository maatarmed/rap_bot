{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('rap_bot')",
   "display_name": "Python 3.7.9 64-bit ('rap_bot')",
   "metadata": {
    "interpreter": {
     "hash": "bd0ea8ad827037fad796260c4321c3e1f3a79866121dd91c2d1fdcf1701d5bf1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "import requests\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "\n",
    "# DB connexion\n",
    "global client\n",
    "client = MongoClient(port=27017)\n",
    "global db\n",
    "db = client.GeniusScrappingProject\n",
    "\n",
    "API_BASE = \"https://api.genius.com\"\n",
    "API_CLIENT_ACCESS_TOKEN = \"w7XemCkBJW-a0eT5RZ3bjHKt9-fr-v0RYBYS4iQ_9CtY-uvbJomzCpuqoonzw6jM\"\n",
    "\n",
    "\n",
    "def add_songs(songs):\n",
    "\tif isinstance(songs, list):\n",
    "\t\tfor song, _ in enumerate(songs):\n",
    "\t\t\tprint (song)\n",
    "\t\t\tentry = {\n",
    "\t\t\t\t'id' : int(songs[song]['id']),\n",
    "\t\t\t\t'title' : songs[song]['title'],\n",
    "\t\t\t\t'primary_artist' : {\n",
    "\t\t\t\t\t'id' : songs[song]['primary_artist']['id'],\n",
    "\t\t\t\t\t'name' : songs[song]['primary_artist']['name'],\n",
    "\t\t\t\t\t'url' : songs[song]['primary_artist']['url'],\n",
    "\t\t\t\t\t'is_verified' : songs[song]['primary_artist']['is_verified']\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t'url' : songs[song]['url']\n",
    "\t\t\t\t}\n",
    "\t\t\tprint(songs[song]['album'])\n",
    "\t\t\tif songs[song]['album']:\n",
    "\t\t\t\tentry['album'] = {\n",
    "\t\t\t\t\t'id': songs[song]['album']['id'], \n",
    "\t\t\t\t\t'full_title': songs[song]['album']['full_title'], \n",
    "\t\t\t\t\t'name': songs[song]['album']['name'], \n",
    "\t\t\t\t\t'artist': songs[song]['album']['artist']['id']\n",
    "\t\t\t\t\t}\n",
    "\t\t\tif len(songs[song]['featured_artists']) > 0:\n",
    "\t\t\t\tfeatured_artists = list()\n",
    "\t\t\t\tfor artist in songs[song]['featured_artists']:\n",
    "\t\t\t\t\tart = {\n",
    "\t\t\t\t\t\t'id' : artist['id'],\n",
    "\t\t\t\t\t\t'name' : artist['name']\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\tfeatured_artists.append(art)\n",
    "\t\t\t\tentry['featured_artists'] = featured_artists\n",
    "\t\t\t#Step 3: Insert Artist into MongoDB via isnert_one\n",
    "\t\t\tdb.songs.insert_one(entry)\n",
    "\t\t\tprint('songs {} added with success'.format(songs[song]['title']))\n",
    "\telse:\n",
    "\t\tentry = {\n",
    "\t\t\t'id' : int(songs['id']),\n",
    "\t\t\t'title' : songs['title'],\n",
    "\t\t\t'primary_artist' : {\n",
    "\t\t\t\t'id' : songs['primary_artist']['id'],\n",
    "\t\t\t\t'name' : songs['primary_artist']['name'],\n",
    "\t\t\t\t'url' : songs['primary_artist']['url'],\n",
    "\t\t\t\t'is_verified' : songs['primary_artist']['is_verified']\n",
    "\t\t\t\t},\n",
    "\t\t\t'url' : songs['url'],\n",
    "\t\t\t'album': {\n",
    "\t\t\t\t'id': songs['album']['id'], \n",
    "\t\t\t\t'full_title': songs['album']['full_title'], \n",
    "\t\t\t\t'name': songs['album']['name'], \n",
    "\t\t\t\t'artist': songs['album']['artist']['id']\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\tif len(songs['featured_artists']) > 0:\n",
    "\t\t\tfeatured_artists = list()\n",
    "\t\t\tfor artist in songs['featured_artists']:\n",
    "\t\t\t\tart = {\n",
    "\t\t\t\t\t'id' : artist['id'],\n",
    "\t\t\t\t\t'name' : artist['name']\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\tfeatured_artists.append(art)\n",
    "\t\tentry['featured_artists'] = featured_artists\n",
    "\n",
    "\t\tdb.songs.insert_one(entry)\n",
    "\t\tprint('songs {} added with success'.format(songs['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(path, params=None, headers=None):\n",
    "    \"\"\"\n",
    "    Generate Request URL and Get response object from querying the genius API\n",
    "\n",
    "    Args:\n",
    "        path (string): url to get data from\n",
    "        params (optional): request parameters. Defaults to None.\n",
    "        headers (optional): check if Authorization existes create one otherwise. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        json : request result\n",
    "    \"\"\"\n",
    "    # Generate request URL\n",
    "    requrl = '/'.join([API_BASE, path])\n",
    "    token = \"Bearer {}\".format(API_CLIENT_ACCESS_TOKEN)\n",
    "    if headers:\n",
    "        headers['Authorization'] = token\n",
    "    else:\n",
    "        headers = {\"Authorization\": token}\n",
    "    # Get response object from querying genius api\n",
    "    response = requests.get(url=requrl, params=params, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_songs_id(artist_id):\n",
    "    \"\"\"\n",
    "    Retrieve all the songs IDs of an artist\n",
    "\n",
    "    Args:\n",
    "        artist_id (Int): THe artist's ID\n",
    "\n",
    "    Returns:\n",
    "        List: all the songs that the artist is the primary one\n",
    "    \"\"\"\n",
    "    #Get all the song id from an artist.#\n",
    "    current_page = 1\n",
    "    next_page = True\n",
    "    songs = []  # to store final song ids\n",
    "\n",
    "    while next_page:\n",
    "        path = \"artists/{}/songs/\".format(artist_id)\n",
    "        params = {'page': current_page}  # the current page\n",
    "        data = get_json(path=path, params=params)  # get json of songs\n",
    "        page_songs = data['response']['songs']\n",
    "        if page_songs:\n",
    "            # Add all the songs of current page\n",
    "            songs += page_songs\n",
    "            # Increment current_page value for next loop\n",
    "            current_page += 1\n",
    "            print(\"Page {} finished scraping\".format(current_page))\n",
    "            # If you don't wanna wait too long to scrape, un-comment this\n",
    "            # if current_page == 2:\n",
    "            #   break\n",
    "        else:\n",
    "            # If page_songs is empty, quit\n",
    "            next_page = False\n",
    "\n",
    "    print(\"Song id were scraped from {} pages\".format(current_page))\n",
    "\n",
    "    # Get all the song ids, excluding not-primary-artist songs.\n",
    "    songs = [song[\"id\"] for song in songs]\n",
    "    # if song[\"primary_artist\"][\"id\"] == artist_id\n",
    "\n",
    "    return songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, typee='artist'):\n",
    "    \"\"\"\n",
    "    This is a one function to get data through the Genius API\n",
    "\n",
    "    Args:\n",
    "        typee (string) : takes one of the following values : artist - song\n",
    "        query (string / int) : string when type search, int otherwise\n",
    "\n",
    "    Returns:\n",
    "        dict: the full data\n",
    "    \"\"\"\n",
    "    if typee == 'artist' or typee == 'song':\n",
    "        assert str(query).isdecimal()\n",
    "        url = '{0}s/{1}'.format(typee, query)\n",
    "        request = get_json(url)\n",
    "        data = request['response'][typee]\n",
    "    else:\n",
    "        url = 'search?access_token={0}&q={1}'.format(API_CLIENT_ACCESS_TOKEN, query)\n",
    "        request = get_json(url)\n",
    "        data = request['response']['hits']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Page 42 finished scraping\n",
      "Page 43 finished scraping\n",
      "Page 44 finished scraping\n",
      "Page 45 finished scraping\n",
      "Page 46 finished scraping\n",
      "Page 47 finished scraping\n",
      "Page 48 finished scraping\n",
      "Page 49 finished scraping\n",
      "Page 50 finished scraping\n",
      "Page 51 finished scraping\n",
      "Page 52 finished scraping\n",
      "Page 53 finished scraping\n",
      "Page 54 finished scraping\n",
      "Page 55 finished scraping\n",
      "Page 56 finished scraping\n",
      "Page 57 finished scraping\n",
      "Page 58 finished scraping\n",
      "Page 59 finished scraping\n",
      "Page 60 finished scraping\n",
      "Page 61 finished scraping\n",
      "Page 62 finished scraping\n",
      "Page 63 finished scraping\n",
      "Page 64 finished scraping\n",
      "Song id were scraped from 64 pages\n"
     ]
    }
   ],
   "source": [
    "songs = get_artist_songs_id(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4182181\nNone\n{'id': 4182181, 'title': '12 Days of Diss-Mas', 'primary_artist': {'id': 45, 'name': 'Eminem', 'url': 'https://genius.com/artists/Eminem', 'is_verified': True}, 'url': 'https://genius.com/Eminem-12-days-of-diss-mas-lyrics'}\n"
     ]
    }
   ],
   "source": [
    "if isinstance(songs, list):\n",
    "  for song_id in songs:\n",
    "      song = search(song_id, 'song')\n",
    "      print(song_id)\n",
    "      entry = {\n",
    "          'id' : int(song['id']),\n",
    "          'title' : song['title'],\n",
    "          'primary_artist' : {\n",
    "              'id' : song['primary_artist']['id'],\n",
    "\t\t      'name' : song['primary_artist']['name'],\n",
    "\t\t      'url' : song['primary_artist']['url'],\n",
    "\t          'is_verified' : song['primary_artist']['is_verified']\n",
    "\t\t      },\n",
    "\t\t  'url' : song['url']\n",
    "\t\t  }\n",
    "      if song['album']:\n",
    "          entry['album'] = {\n",
    "              'id': song['album']['id'], \n",
    "              'full_title': song['album']['full_title'], \n",
    "              'name': song['album']['name'], \n",
    "              'artist': song['album']['artist']['id']\n",
    "              }\n",
    "      if len(song['featured_artists']) > 0:\n",
    "          featured_artists = list()\n",
    "          for artist in song['featured_artists']:\n",
    "              art = {\n",
    "                  'id' : artist['id'],\n",
    "                  'name' : artist['name']\n",
    "                  }\n",
    "              featured_artists.append(art)\n",
    "          entry['featured_artists'] = featured_artists\n",
    "      print (entry)\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1203\n"
     ]
    }
   ],
   "source": [
    "print(len(songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_artist(artist):\n",
    "    if artist['id'] == 45:\n",
    "        entry = {\n",
    "            'id' : int(artist['id']),\n",
    "            'name' : artist['name'],\n",
    "            'is_verified' : artist['is_verified'],\n",
    "            'url' : artist['url'],\n",
    "            'songs' : songs\n",
    "            }\n",
    "    else:\n",
    "        entry = {\n",
    "            'id' : int(artist['id']),\n",
    "            'name' : artist['name'],\n",
    "            'is_verified' : artist['is_verified'],\n",
    "            'url' : artist['url'],\n",
    "            'songs' : get_artist_songs_id(artist['id'])\n",
    "            }\n",
    "\t\t\t#Step 3: Insert Artist into MongoDB via isnert_one\n",
    "        db.artists.insert_one(entry)\n",
    "\n",
    "def add_artists(artists):\n",
    "    if isinstance(artists, list):\n",
    "        for artist_id in artists:\n",
    "            artist = search(artist_id)\n",
    "            add_artist(artist)\n",
    "            print('artists {} added with success'.format(artist['name']))\n",
    "    else:\n",
    "        artist = search(artists)\n",
    "        add_artist(artist)\n",
    "        print('artists {} added with success'.format(artist['name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "artists Eminem added with success\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Page 42 finished scraping\n",
      "Page 43 finished scraping\n",
      "Page 44 finished scraping\n",
      "Page 45 finished scraping\n",
      "Page 46 finished scraping\n",
      "Page 47 finished scraping\n",
      "Page 48 finished scraping\n",
      "Song id were scraped from 48 pages\n",
      "artists Nas added with success\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Page 42 finished scraping\n",
      "Page 43 finished scraping\n",
      "Page 44 finished scraping\n",
      "Page 45 finished scraping\n",
      "Page 46 finished scraping\n",
      "Page 47 finished scraping\n",
      "Page 48 finished scraping\n",
      "Page 49 finished scraping\n",
      "Page 50 finished scraping\n",
      "Page 51 finished scraping\n",
      "Page 52 finished scraping\n",
      "Page 53 finished scraping\n",
      "Page 54 finished scraping\n",
      "Page 55 finished scraping\n",
      "Page 56 finished scraping\n",
      "Page 57 finished scraping\n",
      "Page 58 finished scraping\n",
      "Page 59 finished scraping\n",
      "Song id were scraped from 59 pages\n",
      "artists Drake added with success\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Page 42 finished scraping\n",
      "Page 43 finished scraping\n",
      "Page 44 finished scraping\n",
      "Page 45 finished scraping\n",
      "Page 46 finished scraping\n",
      "Page 47 finished scraping\n",
      "Page 48 finished scraping\n",
      "Page 49 finished scraping\n",
      "Page 50 finished scraping\n",
      "Page 51 finished scraping\n",
      "Page 52 finished scraping\n",
      "Page 53 finished scraping\n",
      "Page 54 finished scraping\n",
      "Page 55 finished scraping\n",
      "Page 56 finished scraping\n",
      "Page 57 finished scraping\n",
      "Page 58 finished scraping\n",
      "Page 59 finished scraping\n",
      "Page 60 finished scraping\n",
      "Page 61 finished scraping\n",
      "Page 62 finished scraping\n",
      "Page 63 finished scraping\n",
      "Page 64 finished scraping\n",
      "Page 65 finished scraping\n",
      "Page 66 finished scraping\n",
      "Page 67 finished scraping\n",
      "Page 68 finished scraping\n",
      "Page 69 finished scraping\n",
      "Page 70 finished scraping\n",
      "Page 71 finished scraping\n",
      "Page 72 finished scraping\n",
      "Page 73 finished scraping\n",
      "Page 74 finished scraping\n",
      "Page 75 finished scraping\n",
      "Page 76 finished scraping\n",
      "Page 77 finished scraping\n",
      "Page 78 finished scraping\n",
      "Page 79 finished scraping\n",
      "Page 80 finished scraping\n",
      "Page 81 finished scraping\n",
      "Page 82 finished scraping\n",
      "Page 83 finished scraping\n",
      "Page 84 finished scraping\n",
      "Page 85 finished scraping\n",
      "Page 86 finished scraping\n",
      "Page 87 finished scraping\n",
      "Page 88 finished scraping\n",
      "Page 89 finished scraping\n",
      "Page 90 finished scraping\n",
      "Page 91 finished scraping\n",
      "Page 92 finished scraping\n",
      "Page 93 finished scraping\n",
      "Page 94 finished scraping\n",
      "Page 95 finished scraping\n",
      "Page 96 finished scraping\n",
      "Page 97 finished scraping\n",
      "Page 98 finished scraping\n",
      "Page 99 finished scraping\n",
      "Page 100 finished scraping\n",
      "Page 101 finished scraping\n",
      "Page 102 finished scraping\n",
      "Page 103 finished scraping\n",
      "Page 104 finished scraping\n",
      "Page 105 finished scraping\n",
      "Page 106 finished scraping\n",
      "Page 107 finished scraping\n",
      "Page 108 finished scraping\n",
      "Page 109 finished scraping\n",
      "Page 110 finished scraping\n",
      "Page 111 finished scraping\n",
      "Page 112 finished scraping\n",
      "Page 113 finished scraping\n",
      "Page 114 finished scraping\n",
      "Page 115 finished scraping\n",
      "Page 116 finished scraping\n",
      "Page 117 finished scraping\n",
      "Page 118 finished scraping\n",
      "Page 119 finished scraping\n",
      "Page 120 finished scraping\n",
      "Page 121 finished scraping\n",
      "Page 122 finished scraping\n",
      "Page 123 finished scraping\n",
      "Page 124 finished scraping\n",
      "Page 125 finished scraping\n",
      "Page 126 finished scraping\n",
      "Page 127 finished scraping\n",
      "Page 128 finished scraping\n",
      "Page 129 finished scraping\n",
      "Page 130 finished scraping\n",
      "Page 131 finished scraping\n",
      "Page 132 finished scraping\n",
      "Page 133 finished scraping\n",
      "Page 134 finished scraping\n",
      "Page 135 finished scraping\n",
      "Page 136 finished scraping\n",
      "Page 137 finished scraping\n",
      "Song id were scraped from 137 pages\n",
      "artists Lil Wayne added with success\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Page 42 finished scraping\n",
      "Page 43 finished scraping\n",
      "Page 44 finished scraping\n",
      "Page 45 finished scraping\n",
      "Page 46 finished scraping\n",
      "Page 47 finished scraping\n",
      "Page 48 finished scraping\n",
      "Page 49 finished scraping\n",
      "Page 50 finished scraping\n",
      "Page 51 finished scraping\n",
      "Page 52 finished scraping\n",
      "Page 53 finished scraping\n",
      "Page 54 finished scraping\n",
      "Page 55 finished scraping\n",
      "Page 56 finished scraping\n",
      "Page 57 finished scraping\n",
      "Page 58 finished scraping\n",
      "Page 59 finished scraping\n",
      "Page 60 finished scraping\n",
      "Page 61 finished scraping\n",
      "Page 62 finished scraping\n",
      "Page 63 finished scraping\n",
      "Page 64 finished scraping\n",
      "Page 65 finished scraping\n",
      "Page 66 finished scraping\n",
      "Page 67 finished scraping\n",
      "Page 68 finished scraping\n",
      "Page 69 finished scraping\n",
      "Page 70 finished scraping\n",
      "Page 71 finished scraping\n",
      "Page 72 finished scraping\n",
      "Page 73 finished scraping\n",
      "Page 74 finished scraping\n",
      "Page 75 finished scraping\n",
      "Page 76 finished scraping\n",
      "Page 77 finished scraping\n",
      "Page 78 finished scraping\n",
      "Page 79 finished scraping\n",
      "Page 80 finished scraping\n",
      "Page 81 finished scraping\n",
      "Page 82 finished scraping\n",
      "Page 83 finished scraping\n",
      "Page 84 finished scraping\n",
      "Page 85 finished scraping\n",
      "Page 86 finished scraping\n",
      "Page 87 finished scraping\n",
      "Page 88 finished scraping\n",
      "Page 89 finished scraping\n",
      "Page 90 finished scraping\n",
      "Page 91 finished scraping\n",
      "Page 92 finished scraping\n",
      "Page 93 finished scraping\n",
      "Page 94 finished scraping\n",
      "Page 95 finished scraping\n",
      "Page 96 finished scraping\n",
      "Page 97 finished scraping\n",
      "Song id were scraped from 97 pages\n",
      "artists Kanye West added with success\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Page 28 finished scraping\n",
      "Page 29 finished scraping\n",
      "Page 30 finished scraping\n",
      "Page 31 finished scraping\n",
      "Page 32 finished scraping\n",
      "Page 33 finished scraping\n",
      "Page 34 finished scraping\n",
      "Page 35 finished scraping\n",
      "Page 36 finished scraping\n",
      "Page 37 finished scraping\n",
      "Page 38 finished scraping\n",
      "Page 39 finished scraping\n",
      "Page 40 finished scraping\n",
      "Page 41 finished scraping\n",
      "Page 42 finished scraping\n",
      "Page 43 finished scraping\n",
      "Page 44 finished scraping\n",
      "Page 45 finished scraping\n",
      "Page 46 finished scraping\n",
      "Page 47 finished scraping\n",
      "Page 48 finished scraping\n",
      "Page 49 finished scraping\n",
      "Page 50 finished scraping\n",
      "Page 51 finished scraping\n",
      "Page 52 finished scraping\n",
      "Page 53 finished scraping\n",
      "Page 54 finished scraping\n",
      "Page 55 finished scraping\n",
      "Page 56 finished scraping\n",
      "Page 57 finished scraping\n",
      "Page 58 finished scraping\n",
      "Page 59 finished scraping\n",
      "Page 60 finished scraping\n",
      "Page 61 finished scraping\n",
      "Song id were scraped from 61 pages\n",
      "artists 2Pac added with success\n",
      "Page 2 finished scraping\n",
      "Page 3 finished scraping\n",
      "Page 4 finished scraping\n",
      "Page 5 finished scraping\n",
      "Page 6 finished scraping\n",
      "Page 7 finished scraping\n",
      "Page 8 finished scraping\n",
      "Page 9 finished scraping\n",
      "Page 10 finished scraping\n",
      "Page 11 finished scraping\n",
      "Page 12 finished scraping\n",
      "Page 13 finished scraping\n",
      "Page 14 finished scraping\n",
      "Page 15 finished scraping\n",
      "Page 16 finished scraping\n",
      "Page 17 finished scraping\n",
      "Page 18 finished scraping\n",
      "Page 19 finished scraping\n",
      "Page 20 finished scraping\n",
      "Page 21 finished scraping\n",
      "Page 22 finished scraping\n",
      "Page 23 finished scraping\n",
      "Page 24 finished scraping\n",
      "Page 25 finished scraping\n",
      "Page 26 finished scraping\n",
      "Page 27 finished scraping\n",
      "Song id were scraped from 27 pages\n",
      "artists The Notorious B.I.G. added with success\n"
     ]
    }
   ],
   "source": [
    "add_artists([45, 56, 130, 4, 72, 59, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}